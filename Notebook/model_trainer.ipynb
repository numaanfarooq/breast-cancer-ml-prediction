{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e46c3ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier \n",
    "from sklearn.ensemble import BaggingClassifier \n",
    "from sklearn.ensemble import VotingClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c41d6894",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"Data/preprocessed_breast_cancer_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8079b11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Classification', axis=1)\n",
    "y = df['Classification']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6abcb3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'Voting Classifier': VotingClassifier(estimators=[\n",
    "        ('lr', LogisticRegression()),\n",
    "        ('dt', DecisionTreeClassifier()),\n",
    "        ('rf', RandomForestClassifier()),\n",
    "        ('svm', SVC())\n",
    "    ]),\n",
    "    'Bagging Classifier': BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10),\n",
    "    'AdaBoost Classifier': AdaBoostClassifier(n_estimators=50),\n",
    "    'Gradient Boosting Classifier': GradientBoostingClassifier(n_estimators=100)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c6d61e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted):\n",
    "    accuracy= accuracy_score(true, predicted)\n",
    "    precision = precision_score(true, predicted)\n",
    "    recall = recall_score(true, predicted)\n",
    "    f1 = f1_score(true, predicted)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f646f482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.7609\n",
      "- Precision: 0.7045\n",
      "- Recall: 0.7750\n",
      "- F1 Score: 0.7381\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8750\n",
      "- Precision: 0.8462\n",
      "- Recall: 0.9167\n",
      "- F1 Score: 0.8800\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- F1 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7917\n",
      "- Precision: 0.8182\n",
      "- Recall: 0.7500\n",
      "- F1 Score: 0.7826\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- F1 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8333\n",
      "- Precision: 0.9000\n",
      "- Recall: 0.7500\n",
      "- F1 Score: 0.8182\n",
      "===================================\n",
      "\n",
      "\n",
      "Support Vector Machine\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8804\n",
      "- Precision: 0.8718\n",
      "- Recall: 0.8500\n",
      "- F1 Score: 0.8608\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9167\n",
      "- Precision: 0.9167\n",
      "- Recall: 0.9167\n",
      "- F1 Score: 0.9167\n",
      "===================================\n",
      "\n",
      "\n",
      "Voting Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9457\n",
      "- Precision: 0.8889\n",
      "- Recall: 1.0000\n",
      "- F1 Score: 0.9412\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9167\n",
      "- Precision: 0.8571\n",
      "- Recall: 1.0000\n",
      "- F1 Score: 0.9231\n",
      "===================================\n",
      "\n",
      "\n",
      "Bagging Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- F1 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7083\n",
      "- Precision: 0.6923\n",
      "- Recall: 0.7500\n",
      "- F1 Score: 0.7200\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ossum\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- F1 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.7500\n",
      "- Precision: 0.6875\n",
      "- Recall: 0.9167\n",
      "- F1 Score: 0.7857\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- F1 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8750\n",
      "- Precision: 1.0000\n",
      "- Recall: 0.7500\n",
      "- F1 Score: 0.8571\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_list = []\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "# Loop through each model\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    train_accuracy, train_precision, train_recall, train_f1 = evaluate_model(y_train, y_train_pred)\n",
    "    test_accuracy, test_precision, test_recall, test_f1 = evaluate_model(y_test, y_test_pred)\n",
    "    \n",
    "    # Print evaluation results\n",
    "    print(name)\n",
    "    model_list.append(name)\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Accuracy: {:.4f}\".format(train_accuracy))\n",
    "    print(\"- Precision: {:.4f}\".format(train_precision))\n",
    "    print(\"- Recall: {:.4f}\".format(train_recall))\n",
    "    print(\"- F1 Score: {:.4f}\".format(train_f1))\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Accuracy: {:.4f}\".format(test_accuracy))\n",
    "    print(\"- Precision: {:.4f}\".format(test_precision))\n",
    "    print(\"- Recall: {:.4f}\".format(test_recall))\n",
    "    print(\"- F1 Score: {:.4f}\".format(test_f1))\n",
    "    \n",
    "    # Append evaluation results to lists\n",
    "    accuracy_list.append(test_accuracy)\n",
    "    precision_list.append(test_precision)\n",
    "    recall_list.append(test_recall)\n",
    "    f1_list.append(test_f1)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74d9d81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_model.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(model, 'n svm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c460da39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a3886a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8766ee7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f04c845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60df7be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
